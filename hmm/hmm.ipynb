{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import collections\n",
    "import itertools\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "np.set_printoptions(2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "sos = '<s>'\n",
    "eos = '</s>'\n",
    "unk = '<unk>'\n",
    "def read_docs(dataset_year, max_docs_count: int):\n",
    "  is_doc = False\n",
    "  docs_count = 0\n",
    "\n",
    "  with open(f'dataset/cg.Folha.{dataset_year}', encoding='windows-1252') as file: \n",
    "    for line in file:\n",
    "      if docs_count >= max_docs_count:\n",
    "        break\n",
    "\n",
    "      if line.startswith('<DOC>'):\n",
    "        is_doc = True\n",
    "        continue\n",
    "\n",
    "      if line.startswith('</DOC>'):\n",
    "        is_doc = False\n",
    "        docs_count += 1\n",
    "        continue\n",
    "\n",
    "      if is_doc is False:\n",
    "        continue\n",
    "\n",
    "      if line.startswith(sos):\n",
    "        yield (sos, sos)\n",
    "      elif line.startswith(eos):\n",
    "        yield (eos, eos)\n",
    "      else:\n",
    "        splitted_line = line.split('\\t')\n",
    "        if len(splitted_line) == 2:\n",
    "          word = splitted_line[0]\n",
    "          tag = list(filter(lambda x: re.match(r'^[A-Z]', x), splitted_line[1].split()))[0]\n",
    "          yield (word, tag)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def get_transition_counter(tags):\n",
    "  current_it, next_it = itertools.tee(tags)\n",
    "  next(next_it)\n",
    "\n",
    "  counter = collections.Counter(list(zip(current_it, next_it)))\n",
    "\n",
    "  return counter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def train(dataset):\n",
    "  word_tag_counter = collections.Counter()\n",
    "  tag_counter = collections.Counter()\n",
    "  transition_counter = collections.Counter()\n",
    "  sentence_tags = []\n",
    "\n",
    "  for word, tag in dataset:\n",
    "    tag_counter.update({ tag: 1 })\n",
    "    word_tag_counter.update({ (word, tag): 1 })\n",
    "    \n",
    "    sentence_tags.append(tag)\n",
    "    if tag == eos:\n",
    "      transition_counter += get_transition_counter(sentence_tags)\n",
    "      sentence_tags = []\n",
    "\n",
    "  words_count = sum(word_tag_counter.values())\n",
    "  tag_counter.update({ unk: round(words_count * 0.05) })\n",
    "\n",
    "  return {\n",
    "    'word_tag_counter': word_tag_counter,\n",
    "    'tag_counter': tag_counter,\n",
    "    'transition_counter': transition_counter\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def emission_probability(model, word_tag):\n",
    "  words_count = len(set([word for (word, _) in model['word_tag_counter'].keys()]))\n",
    "  tag_count = model['tag_counter'][word_tag[1]]\n",
    "\n",
    "  return (model['word_tag_counter'][word_tag] + 1) / (tag_count + words_count)\n",
    "\n",
    "def transition_probability(model, tag_transition):\n",
    "  words_count = len(set([word for (word, _) in model['word_tag_counter'].keys()]))\n",
    "  tag_count = model['tag_counter'][tag_transition[0]]\n",
    "  return (model['transition_counter'][tag_transition] + 1) / (tag_count + words_count)\n",
    "\n",
    "def get_initial_probability(model):\n",
    "  initial_prob = { sos: 1 }\n",
    "  for tag in model['tag_counter'].keys():\n",
    "    if tag == sos:\n",
    "      continue\n",
    "    \n",
    "    initial_prob.update({ tag: 0 })\n",
    "\n",
    "  return initial_prob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def viterbi(model, word_tags):\n",
    "  initial_probability = get_initial_probability(model)\n",
    "  tags = list(model['tag_counter'].keys())\n",
    "  probability_matrix = np.zeros((len(tags), len(word_tags)))\n",
    "  tag_matrix = np.full((len(tags), len(word_tags)), '', dtype=object)\n",
    "\n",
    "  for index, tag in enumerate(tags):\n",
    "    probability_matrix[index, 0] = initial_probability[tag] * emission_probability(model, word_tags[0])\n",
    "\n",
    "  for idx_word_tag in range(1, len(word_tags)):\n",
    "    for idx_next_tag, next_tag in enumerate(tags):\n",
    "      for idx_current_tag, current_tag in enumerate(tags):\n",
    "        current_prob = probability_matrix[idx_current_tag, idx_word_tag - 1] * transition_probability(model, (current_tag, next_tag)) * emission_probability(model, (word_tags[idx_word_tag][0], next_tag))\n",
    "        if probability_matrix[idx_next_tag, idx_word_tag] < current_prob:\n",
    "          probability_matrix[idx_next_tag, idx_word_tag] = current_prob\n",
    "          tag_matrix[idx_next_tag, idx_word_tag] = idx_current_tag\n",
    "\n",
    "  predict_tag_index = int(np.argmax(probability_matrix[:, -1]))\n",
    "  predict_tags_indexes = [predict_tag_index]\n",
    "  for idx in range(len(word_tags) - 1, 0, -1):\n",
    "    predict_tag_index = int(tag_matrix[predict_tag_index, idx])\n",
    "    predict_tags_indexes.append(predict_tag_index)\n",
    "\n",
    "  predict_tags = [tags[i] for i in reversed(predict_tags_indexes)]\n",
    "\n",
    "  return predict_tags"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "model = train(read_docs('1995', max_docs_count=100))\n",
    "\n",
    "word_tag_acc = []\n",
    "sentences = []\n",
    "for word_tag in read_docs('1994', max_docs_count=1):\n",
    "  word_tag_acc.append(word_tag)\n",
    "  if word_tag[0] == eos:\n",
    "    sentences.append(word_tag_acc)\n",
    "    word_tag_acc = []\n",
    "\n",
    "for s in itertools.islice(sentences, 5):\n",
    "  target = [tag for _, tag in s]\n",
    "  predict = viterbi(model, s)\n",
    "  print(f'----------\\ntarget {target}\\npredict {predict}\\n----------')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------\n",
      "target ['<s>', 'PROP', 'V', 'PRP', 'DET', 'NUM', 'ADJ', 'N', 'PRP', 'DET', 'N', 'PRP', 'NUM', 'N', 'PRP', 'N', 'V', 'DET', 'N', 'PRP', 'PROP', 'PROP', 'PU', 'PROP', 'PU', 'ADV', 'DET', 'ADV', 'ADJ', 'PU', 'NUM', 'PRP', 'ADJ', 'N', 'ADJ', 'PU', 'V', 'PRP', 'PROP', 'PU', 'PROP', 'PU', 'PRP', 'PROP', 'PRP', 'NUM', 'PRP', 'N', 'PU', 'PU', '</s>']\n",
      "predict ['<s>', 'DET', 'N', 'PRP', 'DET', 'N', 'ADJ', 'N', 'PRP', 'DET', 'N', 'PRP', 'DET', 'N', 'PRP', 'N', 'PRP', 'DET', 'N', 'PRP', 'DET', 'N', 'PU', 'PU', 'PU', 'ADV', 'DET', 'DET', 'N', 'PU', 'V', 'PRP', 'N', 'KC', 'ADJ', 'PU', 'V', 'PRP', 'N', 'PU', 'PU', 'PU', 'PRP', 'PROP', 'PRP', 'N', 'PRP', 'N', 'PU', 'PU', '</s>']\n",
      "----------\n",
      "----------\n",
      "target ['<s>', 'DET', 'N', 'PROP', 'PU', 'PROP', 'PU', 'PRP', 'DET', 'PROP', 'PRP', 'NUM', 'PRP', 'ADJ', 'N', 'ADJ', 'PU', 'PROP', 'PU', 'N', 'PU', 'PRP', 'PROP', 'PRP', 'NUM', 'KC', 'PROP', 'PU', 'PROP', 'PU', 'PRP', 'PROP', 'PRP', 'NUM', 'V', 'DET', 'ADJ', 'N', 'PU', 'PU', '</s>']\n",
      "predict ['<s>', 'DET', 'N', 'PU', 'PU', 'PU', 'PU', 'PRP', 'DET', 'N', 'PRP', 'N', 'PRP', 'N', 'KC', 'N', 'PU', 'PU', 'PU', 'PU', 'PU', 'PRP', 'N', 'PRP', 'N', 'KC', 'PROP', 'PU', 'PU', 'PU', 'PRP', 'PROP', 'PRP', 'DET', 'N', 'PRP', 'DET', 'N', 'PU', 'PU', '</s>']\n",
      "----------\n",
      "----------\n",
      "target ['<s>', 'DET', 'PROP', 'V', 'V', 'N', 'PRP', 'DET', 'N', 'PRP', 'PROP', 'PRP', 'N', 'V', 'PRP', 'DET', 'N', 'PROP', 'PU', 'PU', '</s>']\n",
      "predict ['<s>', 'DET', 'N', 'V', 'DET', 'N', 'PRP', 'DET', 'N', 'PRP', 'PROP', 'PRP', 'DET', 'N', 'PRP', 'DET', 'N', 'PU', 'PU', 'PU', '</s>']\n",
      "----------\n",
      "----------\n",
      "target ['<s>', 'PROP', 'KC', 'PROP', 'PU', '</s>']\n",
      "predict ['<s>', 'PROP', 'KC', 'N', 'PU', '</s>']\n",
      "----------\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}